# ML-Playground

## ğŸš€ Machine Learning Algorithms from Scratch in Python

Welcome to **ML-Playground**, a collection of core machine learning algorithms implemented from scratch using Python.  
Perfect for beginners, students, and anyone who wants to understand the inner workings of ML models.

---

## ğŸŒŸ Featured Algorithms

### 1. ğŸ”¹ Linear Regression

**Implemented using Gradient Descent**

**Key Features:**
- ğŸ’¡ Flexible execution using `ArgumentParser`
- ğŸ› ï¸ Preprocessing options:
  - `0`: No preprocessing  
  - `1`: Min/Max scaling  
  - `2`: Standardization
- ğŸ§  Training choices:
  - `0`: Verify a perfect 45-degree linear line  
  - `1`: Train with all features  
  - `2`: Train with the best feature  
  - `3`: Solve using Normal Equations  
  - `4`: Solve using Scikit-Learn
- âš™ï¸ Adjustable parameters:
  - `--step_size`: Learning rate  
  - `--precision`: Requested precision  
  - `--max_iter`: Maximum number of iterations (epochs)  
  - `--dataset`: Path to dataset file

---

### 2. ğŸ”¹ K-Nearest Neighbors (KNN) Classifier

**From-scratch implementation of a classic classification algorithm**

**Key Features:**
- ğŸ“ Distance metrics supported:
  - âœ… Euclidean distance (`euclidean`)
  - âœ… Cosine similarity (`cosine`) 
  - âœ… Manhattan distance (`manhattan`)
- ğŸ”¢ Flexible neighbor selection with adjustable `k` value
- ğŸŒˆ Visualizations of decision boundaries
- ğŸŒ¼ High accuracy (95%+) on the Iris dataset


---

### 3. ğŸ”¹ Linear & Logistic Regression (Jupyter Notebook)

**Notebook:** `LinearRegression&LogisticRegression.ipynb`  
An interactive exploration of regression using multiple optimization strategies.

**Whatâ€™s inside:**
- ğŸ“Š Data generation and splitting
- ğŸ“‰ **Linear Regression** with:
  - Batch Gradient Descent  
  - Stochastic Gradient Descent  
  - Mini-batch Gradient Descent
- ğŸ” **Logistic Regression** with:
  - Batch Gradient Descent  
  - Stochastic Gradient Descent  
  - Mini-batch Gradient Descent


