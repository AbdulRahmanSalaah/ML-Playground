# ML-Playground

## ğŸš€ Machine Learning Algorithms from Scratch in Python

Welcome to **ML-Playground**, a collection of core machine learning algorithms implemented from scratch using Python.  
Perfect for beginners, students, and anyone who wants to understand the inner workings of ML models.

---

## ğŸŒŸ Featured Algorithms

### 1. ğŸ”¹ Linear Regression

**Implemented using Gradient Descent**

**Key Features:**
- ğŸ’¡ Flexible execution using `ArgumentParser`
- ğŸ› ï¸ Preprocessing options:
  - `0`: No preprocessing  
  - `1`: Min/Max scaling  
  - `2`: Standardization
- ğŸ§  Training choices:
  - `0`: Verify a perfect 45-degree linear line  
  - `1`: Train with all features  
  - `2`: Train with the best feature  
  - `3`: Solve using Normal Equations  
  - `4`: Solve using Scikit-Learn
- âš™ï¸ Adjustable parameters:
  - `--step_size`: Learning rate  
  - `--precision`: Requested precision  
  - `--max_iter`: Maximum number of iterations (epochs)  
  - `--dataset`: Path to dataset file

---

### 2. ğŸ”¹ K-Nearest Neighbors (KNN) Classifier

**From-scratch implementation of a classic classification algorithm**

**Key Features:**
- ğŸ“ Distance metrics supported:
  - âœ… Euclidean distance (`euclidean`)
  - âœ… Cosine similarity (`cosine`) 
  - âœ… Manhattan distance (`manhattan`)
- ğŸ”¢ Flexible neighbor selection with adjustable `k` value
- ğŸŒˆ Visualizations of decision boundaries
- ğŸŒ¼ High accuracy (95%+) on the Iris dataset


---

### 3. ğŸ”¹ Linear & Logistic Regression 

**Notebook:** `LinearRegression&LogisticRegression.ipynb`  
An interactive exploration of regression using multiple optimization strategies.

**Whatâ€™s inside:**
- ğŸ“Š Data generation and splitting
- ğŸ“‰ **Linear Regression** with:
  - Batch Gradient Descent  
  - Stochastic Gradient Descent  
  - Mini-batch Gradient Descent
- ğŸ” **Logistic Regression** with:
  - Batch Gradient Descent  
  - Stochastic Gradient Descent  
  - Mini-batch Gradient Descent
 
  ---

### 4. ğŸ”¹ Voice Gender Classification

A machine learning system that classifies voice recordings as male or female using audio features and ensemble learning techniques.

## Project Overview

This project demonstrates:
- Audio feature extraction (MFCCs, spectral features)
- Custom Gaussian Naive Bayes implementation
- Model comparison with scikit-learn classifiers
- Ensemble methods with Bagging
- Real-time voice prediction capability

## Key Features

- **Audio Processing**:
  - Noise reduction and silence removal
  - MFCC, spectral centroid, rolloff, and ZCR feature extraction
- **Machine Learning Models**:
  - Custom Gaussian Naive Bayes (80% accuracy)
  - Scikit-learn's GaussianNB (80% accuracy)
  - Logistic Regression (86.7% accuracy)
- **Ensemble Learning**:
  - Bagging classifiers with majority voting
  - Achieves 83.3% accuracy

## Results Summary

| Model                  | Accuracy | Precision | Recall | F1-Score |
|------------------------|----------|-----------|--------|----------|
| Custom NB              | 0.8000   | 0.8000    | 0.8000 | 0.8000   |
| Logistic Regression    | 0.8667   | 0.9231    | 0.8000 | 0.8571   |
| Bagging (Logistic)     | 0.8667   | 1.0000    | 0.7333 | 0.8462   |


 
---

